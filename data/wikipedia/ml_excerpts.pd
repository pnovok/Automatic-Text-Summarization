heading,article,neural_abstractive_summary,neural_extractive_summary,classic_extractive_summary,hybrid_extractive_summary,commentary
Front Matter,"Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.  In its application across business problems, machine learning is also referred to as predictive analytics.

"," Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. It is seen as a part of artificial intelligence. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision.","The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.  In its application across business problems, machine learning is also referred to as predictive analytics.","Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.","Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning.  In its application across business problems, machine learning is also referred to as predictive analytics.","
    This segment illustrates how variable automated summaries can be. 
    Each model produces a completely different summary and none of them is technically incorrect. 
    However, some are probably more useful than others. Which one do you most prefer?"
Applications,"There are many applications for machine learning, including:

In 2006, the media-services provider Netflix held the first ""Netflix Prize"" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%.  A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million. Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (""everything is a recommendation"") and they changed their recommendation engine accordingly. In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis. In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors' jobs would be lost in the next two decades to automated machine learning medical diagnostic software. In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists. In 2019 Springer Nature published the first research book created using machine learning. In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19. Machine learning is recently applied to predict the green behavior of human-being. Recently, machine learning technology is also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone."," There are many applications for machine learning, including: prediction of medical doctors' jobs. Netflix held the first ""Netflix Prize"" competition in 2006 to find a program to better predict user preferences and improve the accuracy of its Cinematch movie recommendation algorithm by at least 10%. Machine learning is recently applied to predict the green behavior of human-being.","In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19. Machine learning is recently applied to predict the green behavior of human-being. Recently, machine learning technology is also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone.","There are many applications for machine learning, including:

In 2006, the media-services provider Netflix held the first ""Netflix Prize"" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors' jobs would be lost in the next two decades to automated machine learning medical diagnostic software. In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.","There are many applications for machine learning, including:

In 2006, the media-services provider Netflix held the first ""Netflix Prize"" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19. Machine learning is recently applied to predict the green behavior of human-being.","
    This example highlights a common problem with Neural Abstractive summarization models: 
    factual inconsistency. Notice how the first sentence of the model's summary twists the 
    meaning of the original text. These errors are difficult to detect so determining how often 
    these mistakes occur is challenging. Extractive summarization models generally do not suffer 
    from this problem."
Unsupervised learning,"Unsupervised learning algorithms take a set of data that contains only inputs, and find structure in the data, like grouping or clustering of data points. The algorithms, therefore, learn from test data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. A central application of unsupervised learning is in the field of density estimation in statistics, such as finding the probability density function. Though unsupervised learning encompasses other domains involving summarizing and explaining data features.
Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity."," Unsupervised learning algorithms take a set of data that contains only inputs and find structure in the data. The algorithms learn from test data that has not been labeled, classified or categorized. A central application is in the field of density estimation in statistics, such as finding the probability density function.","Unsupervised learning algorithms take a set of data that contains only inputs, and find structure in the data, like grouping or clustering of data points. The algorithms, therefore, learn from test data that has not been labeled, classified or categorized. A central application of unsupervised learning is in the field of density estimation in statistics, such as finding the probability density function.","Unsupervised learning algorithms take a set of data that contains only inputs, and find structure in the data, like grouping or clustering of data points. 
Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters.","Unsupervised learning algorithms take a set of data that contains only inputs, and find structure in the data, like grouping or clustering of data points. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Though unsupervised learning encompasses other domains involving summarizing and explaining data features.","
    This example highlights where Neural Abstractive summarization models excel: paraphrasing. 
    This model is adept at rewording the original text to include only the most relevant portions 
    of key setences, allowing for a more streamlined summary. By comparison, our extractive models 
    pull full sentences and thus include all the unnecessary wordiness."
Software,Software suites containing a variety of machine learning algorithms include the following:," Software suites containing a variety of machine learning algorithms include the following software suites. Software suites include software suites containing various machine-learning algorithms. Machine-learning software software is available to download and use in software suites such as Google's ""learners' software suites and software suites for machine-learners.",,Software suites containing a variety of machine learning algorithms include the following:,Software suites containing a variety of machine learning algorithms include the following:,"
    We included this example to showcase another drawback of Neural Abstractive models. 
    When given a short piece of text, they can generate summaries that are longer than the input 
    text, making things up as they go along. It may seem to be in line with the original text but
    it's not remaining faithful to the original article. This behavior can be mitigated by 
    controlling the length of the input text or decreasing the length of the model's generated summary."
Proprietary software with free and open-source editions,"KNIME
RapidMiner"," KNIMERapidMiner is a reality TV show. It's also a reality show about mining in the United States. It airs on CNN.com/Heroes on Sunday at 8.30 p.m. ET. For more information, visit http://www.kimim.org/kimidminer.",,"KNIME
RapidMiner","KNIME
RapidMiner","
    If the text is too short, Neural Abstractive models will still attempt a summary but it 
    will be almost completely decoupled from the input text. Instead, the model regurgitates 
    some of it's training data. This behavior can be mitigated by controlling the length of the 
    input text."
History and relationships to other fields,"The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer in the field of computer gaming and artificial intelligence. A representative book of the machine learning research during the 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: ""A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E."" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper ""Computing Machinery and Intelligence"", in which the question ""Can machines think?"" is replaced with the question ""Can machines do what we (as thinking entities) can do?"".Modern day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. Where as, a machine learning algorithm for stock trading may inform the trader of future potential predictions.
As a scientific endeavor, machine learning grew out of the quest for artificial intelligence. In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what was then termed ""neural networks""; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics. Probabilistic reasoning was also employed, especially in automated medical diagnosis.:488However, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.:488 By 1980, expert systems had come to dominate AI, and statistics was out of favor. Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming, but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.:708–710, 755 Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as ""connectionism"", by researchers from other disciplines including Hopfield, Rumelhart and Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.:25Machine learning (ML), reorganized as a separate field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics and probability theory.As of 2020, many sources continue to assert that machine learning remains a subfield of AI. The main disagreement is whether all of ML is part of AI, as this would mean that anyone using ML could claim they are using AI. Others have the view that not all of ML is part of AI where only an 'intelligent' subset of ML is part of AI.The question to what is the difference between ML and AI is answered by Judea Pearl in The Book of Why. Accordingly, ML learns and predicts based on passive observations, whereas AI implies an agent  interacting with the environment to learn and take actions that maximize its chance of successfully achieving its goals.
Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as ""unsupervised learning"" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data."," The term machine learning was coined in 1959 by Arthur Samuel, an IBMer and pioneer in the field of computer gaming and artificial intelligence. Modern day machine learning has two objectives, one is to classify data based on models which have been developed, the other is to make predictions for future outcomes based on these models.
 As a scientific endeavor, machine learning grew out of the quest for artificial intelligence. In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. An increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning.
 Machine learning and data mining often employ the same methods and overlap significantly. While machine learning focuses on prediction, data mining focuses on the discovery of (previously) unknown properties in the data. Data mining uses many machine learning methods, but with different goals. Machine learning also employs data mining methods as ""unsupervised learning"" or as a preprocessing step to improve learner accuracy.","Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. Where as, a machine learning algorithm for stock trading may inform the trader of future potential predictions. By 1980, expert systems had come to dominate AI, and statistics was out of favor.","
Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as ""unsupervised learning"" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge.","As a scientific endeavor, machine learning grew out of the quest for artificial intelligence. In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming, but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.:708–710, 755 Neural networks research had been abandoned by AI and computer science around the same time.","
    In this example, the input text is larger than the Neural Abstractive model can handle. Instead, we chose 
    to split the input into several chunks, allowed the model to summarize each chunk, 
    and then stitched the summaries back together. While this may work for some use cases, it might not always 
    be appropriate. 


    The Neural Extractive model suffers from the same issue, but instead of splitting the text 
    into chunks, the approach here uses _truncation._ This means the model considers 
    only the amount of tokens it can handle at one time and ignores everything that comes after. 
    The summary will only ever come from the top portion of the original document because this 
    model never sees the second half! 


    Finally, the Classic and Hybrid Extractive models do not suffer from these issues at all. They can accept 
    documents of any length, a highly desirable feature."
